{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train_model.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPI0B+wtX6uIHY6O+ezmfjA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ykQFNpW5EPdl"},"outputs":[],"source":["import pickle\n","import numpy as np\n","import pandas as pd\n","import lightgbm as lgb\n","from sklearn.model_selection import train_test_split\n","import shap\n","from sklearn.metrics import roc_auc_score\n","import sklearn.metrics as metrics\n","import matplotlib.pyplot as plt\n","\n","def plot_roc_auc(fpr, tpr, title):\n","    roc_auc = metrics.auc(fpr, tpr)\n","    plt.title(title)\n","    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n","    plt.legend(loc = 'lower right')\n","    plt.plot([0, 1], [0, 1],'r--')\n","    plt.xlim([0, 1])\n","    plt.ylim([0, 1])\n","    plt.ylabel('True Positive Rate')\n","    plt.xlabel('False Positive Rate')\n","    plt.show()\n","  \n","\n","\n","def train_model(X, target_name = 'y', split = 'in_sample', model_type = 'lgb', params = 'default', \n","                objective = 'binary', metric = 'auc', save_path = ''):\n","    '''returns model and saves log parameters'''\n","    \n","    if (split == 'in_sample'):\n","        X_tr, X_val, y_train, y_val = train_test_split(X.drop(columns = target_name), \n","                                                       X[target_name], \n","                                                       test_size = 0.1, random_state = 1926)\n","        \n","    if (split != 'in_sample'):\n","        X_tr = X[X['train'] == 1].drop(columns = [target_name, 'train'])\n","        X_val = X[X['train'] != 1].drop(columns = [target_name, 'train'])\n","        y_train = X[X['train'] == 1][target_name]\n","        y_val = X[X['train'] != 1][target_name]\n","    \n","    if (params == 'default'):\n","        params = {'num_leaves': 54, 'min_data_in_leaf': 79, 'objective': objective,\n","                  'max_depth': 3, 'learning_rate': 0.01, 'boosting': 'gbdt', 'feature_fraction': 1,\n","                  'bagging_freq': 5, 'bagging_fraction': 0.9, 'bagging_seed': 11, 'metric': metric, 'lambda_l1': 0.1,\n","                  'verbosity': -1, 'min_child_weight': 5, 'reg_alpha': 3, 'reg_lambda': 2, 'subsample': 0.8,'seed': 1926}\n","        \n","    if (model_type == 'lgb'):\n","        X_train_lgb = lgb.Dataset(X_tr, label = y_train)\n","        X_val_lgb = lgb.Dataset(X_val, label = y_val)\n","        \n","        print('#'*20 + ' '*5 + 'training with ',X_tr.shape[0], ' '*5 + '#'*20)\n","        print('#'*20 + ' '*5 + 'validating with ',X_val.shape[0], ' '*5 + '#'*20)\n","        \n","        model = lgb.train(params, \n","                          X_train_lgb,\n","                          num_boost_round = 1000,\n","                          valid_sets = [X_train_lgb, X_val_lgb],\n","                          early_stopping_rounds = 20)\n","    if (save_path != ''):\n","        with open(save_path + '/_model.pickle', 'wb') as pfile:\n","            pickle.dump(model, pfile, protocol = pickle.HIGHEST_PROTOCOL)\n","\n","    fpr, tpr, threshold = metrics.roc_curve(X[target_name], model.predict(X.drop(columns = target_name)))\n","    plot_roc_auc(fpr, tpr, f'ROC AUC curve for the train and validation sets')\n","    \n","    return model\n","\n","\n","  \n","\n","\n","\n","def model_report(model, X, target_name = 'y', model_type = 'lgb', save_path = ''):\n","    \n","    if (model_type == 'lgb'):\n","        feat_imp = pd.DataFrame({'feature': model.feature_name(),\n","                                 'cover': model.feature_importance(importance_type='split'),\n","                                 'gain': model.feature_importance(importance_type='gain')}\n","                               ).sort_values('gain', ascending = False)\n","        \n","        explainer = shap.TreeExplainer(model)\n","        shap_values = explainer.shap_values(X.drop(columns = target_name))[0]\n","        shap.summary_plot(shap_values, X.drop(columns = target_name))\n","        \n","        shap_dict = dict(zip(X.drop(columns = target_name).columns, shap_values.sum(axis = 0)))\n","        abs_shap_dict = dict(zip(X.drop(columns = target_name).columns, abs(shap_values).sum(axis = 0)))\n","        feat_imp['sum_shap'] = feat_imp['feature'].map(shap_dict)\n","        feat_imp['abs_shap'] = feat_imp['feature'].map(abs_shap_dict)\n","    \n","    \n","    \n","    tempDf = X.copy()\n","    tempDf['score'] = model.predict(tempDf.drop(columns = target_name)) + np.random.rand(tempDf.shape[0])/1e5\n","    tempDf['decile'] = pd.qcut(tempDf['score'], 10, labels = ['Decile '+ str(i) for i in range(1,11)])\n","    decile = tempDf.groupby('decile').size().reset_index()\n","    decile.columns = ['Decile', '# observations']\n","    decile['Average target'] = decile['Decile'].map(tempDf.groupby('decile')[target_name].mean())\n","    decile['Average score'] = decile['Decile'].map(tempDf.groupby('decile').score.mean())\n","    for feature in feat_imp.feature:\n","        decile[feature] = decile['Decile'].map(tempDf.groupby('decile')[feature].mean())\n","        \n","    \n","    if (save_path != ''):\n","        feat_imp.to_csv(os.path.join(save_path, 'FeatureImportances.csv'), index = False, sep = ';', decimal = ',')\n","        decile.to_csv(os.path.join(save_path, 'DecileAnalysis.csv'), index = False, sep = ';', decimal = ',')\n","    \n","    return feat_imp, decile"]}]}